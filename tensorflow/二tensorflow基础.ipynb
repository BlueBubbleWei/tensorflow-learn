{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "global_step = tf.Variable(0)\n",
    "# 通过eponentiial_decay函数生成学习率\n",
    "learning_rate = tf.train.exponential_decay(0.1, global_step,100,0.96,staircase = True)\n",
    "#使用指数衰减的学习率，在minimize函数中传入global_step 将自动更新\n",
    "learning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习率的设置\n",
    "w = tf.Variable(tf.random_normal([2,1],stddev=1,seed =1))\n",
    "y= tf.matmul(x,w)\n",
    "\n",
    "loss =tf.reduce_mean(tf.square(y_ -y)) + tf.contrib.layers.l2_regularizer(lambda)(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "# 正则化防止过拟合\n",
    "weights = tf.constant([[1.,-2.],[-3.,4.]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.contrib.layers.l1_regularizer(0.5)(weights)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(0.5)(weights)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5层的L2正则化的损失函数\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "#获取一层神经网络边上的权重，并将这个权重的L2正则化损失加入名称为'losses'的集合中\n",
    "def get_weight(shape,l2_weight):\n",
    "#生成一个变量\n",
    "    var = tf.Variable(tf.random_normal(shape),dtype=tf.float32)\n",
    "    # add_to_collection 函数将这个新生成变量的L2正则化损失项加入集合\n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(l2_weight)(var))\n",
    "    return var\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1))\n",
    "\n",
    "#生成模拟数据\n",
    "rdm = RandomState(1)\n",
    "dataset_size =128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "# Y = [[int(x1+x2<1)] for (x1,x2) in X]\n",
    "Y = np.random.randint(0,2,128)\n",
    "Y =[[x] for x in Y]\n",
    "batch_size = 8\n",
    "\n",
    "# 定义了每一层网络节点的个数\n",
    "layer_dimension = [2,10,10,10,1]\n",
    "\n",
    "#神经网络的层数\n",
    "n_layers = len(layer_dimension)\n",
    "\n",
    "# 这个变量维护向前传播时最深层的节点，开始的时候就是输入层\n",
    "cur_layer = x\n",
    "# 当前层的节点个数\n",
    "in_dimension =layer_dimension[0]\n",
    "\n",
    "#通过一个循环来生成5层的全连接的神经网络结构\n",
    "for i in range(1,n_layers):\n",
    "    #lay_dimension[i]为下一层的节点数\n",
    "    out_dimension = layer_dimension[i]\n",
    "    #生成当前层中权重的变量，并将这个变量的L2正则化加入计算图上的集合\n",
    "    weight = get_weight([in_dimension,out_dimension],0.001)\n",
    "    bias = tf.Variable(tf.constant(0.1,shape=[out_dimension]))\n",
    "    cur_layer = tf.nn.relu(tf.matmul(cur_layer,weight)+bias)\n",
    "    in_dimension = out_dimension\n",
    "    \n",
    "# 在定义神经网络前向传播的同时已经将所有的L2正则化损失加入到图上的集合\n",
    "#这里只需要计算刻画模型在训练数据上表现的损失函数\n",
    "mse_loss =tf.reduce_mean(tf.square(y_ -cur_layer))\n",
    "# 将均方误差函数加入到损失函数\n",
    "tf.add_to_collection('losses',mse_loss)\n",
    "#get_collection返回一个列表，这个列表是所有这个集合中的元素，这些元素是损失函数的不同部分，将它们加起来可以得到最终的损失函数\n",
    "loss = tf.add_n(tf.get_collection('losses'))\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    STEPS = 100\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size)%dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        print(sess.run(loss,feed_dict={x:X[start:end],y_:Y[start:end]}))\n",
    "#         print(loss.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[5.0, 4.5]\n",
      "[10.0, 4.555]\n",
      "[10.0, 4.60945]\n"
     ]
    }
   ],
   "source": [
    "#滑动平均模型\n",
    "import tensorflow as tf\n",
    "# 定义一个变量用于计算滑动平均\n",
    "v1 = tf.Variable(0,dtype = tf.float32)\n",
    "# 模拟神经网络中迭代的次数，可以用于动态控制衰减率\n",
    "step = tf.Variable(0,trainable=False)\n",
    "# 定义一个滑动平均类，初始化时给了衰减率（0.99）和控制衰减率的变量step\n",
    "ema = tf.train.ExponentialMovingAverage(0.99,step)\n",
    "# 定义一个更新变量滑动平均的操作，这里是一个列表，每执行一次操作，这个列表中的变量都会更新\n",
    "maintain_average_op = ema.apply([v1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run([v1,ema.average(v1)]))\n",
    "#     更新变量v1的值到5\n",
    "    sess.run(tf.assign(v1,5))\n",
    "    sess.run(maintain_average_op)\n",
    "    \n",
    "    print(sess.run([v1,ema.average(v1)]))\n",
    "    \n",
    "    sess.run(tf.assign(step,10000))\n",
    "    sess.run(tf.assign(v1,10))\n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([v1,ema.average(v1)]))\n",
    "    \n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([v1,ema.average(v1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"d:\\python3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\python3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"d:\\python3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"d:\\python3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-35dfaccb9cfa>\", line 15, in <module>\n    y_ = tf.placeholder(tf.float32,shape=(None,1))\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-4c0f2bb3276b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m#         print('******')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"d:\\python3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\python3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"d:\\python3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"d:\\python3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"d:\\python3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"d:\\python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-35dfaccb9cfa>\", line 15, in <module>\n    y_ = tf.placeholder(tf.float32,shape=(None,1))\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"d:\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "#获取一层神经网络边上的权重，并将这个权重的L2正则化损失加入名称为'losses'的集合中\n",
    "def get_weight(shape,lambda1):\n",
    "    #生成一个变量 \n",
    "    var=tf.Variable(tf.random_normal(shape,stddev=1,seed=1))\n",
    "    #add_to_collection 函数将这个新生成变量的L2正则化损失项加入集合\n",
    "    #这个函数第一个参数losses是集合的名字，第二个参数是要加入这个集合的内容\n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(lambda1)(var))\n",
    "    return var\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "#两个输入节点,回归问题一般只有\n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name=\"x-input\")\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name=\"y-input\")\n",
    "\n",
    "#通过随机数生成一个模拟数据集\n",
    "rdm=RandomState(1)\n",
    "dataset_size=128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "# X=np.array(rdm.rand(dataset_size,2),dtype=np.float32)\n",
    "\n",
    "#设置回归的正确值为两个输入的和加上一个随机量。加上随机量是为了加入不可预测的噪音，否则不同损失函数的意义就不大了\n",
    "#因为不同损失函数都会在能完全预测正确的时候最低。一般来说，噪音为一个均值为0的小量，所以这里噪声设置为-0.05~0.05的随机数\n",
    "Y=[[int(x1+x2<1)] for (x1,x2) in X]\n",
    "# Y =np.array(Y,dtype=np.float32)\n",
    "\n",
    "layer_dimension=[2,10,5,3,1]\n",
    "n_layers=len(layer_dimension)\n",
    "\n",
    "#这个变量维护前向传播时最深层的节点，开始的时候就是输入层\n",
    "cur_layer=x\n",
    "# 当前层的节点个数\n",
    "in_dimension=layer_dimension[0]\n",
    "\n",
    "#通过一个循环来生成5层全连接的神经网络结构\n",
    "for i in range(1,n_layers):\n",
    "    # layer_demension[i]为下一层的节点数\n",
    "    out_dimension=layer_dimension[i]\n",
    "    #生成当前层中权重的变量，并将这个变量的L2正则化损失加入计算图上的集合\n",
    "    weight=get_weight([in_dimension,out_dimension],0.003)\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=[out_dimension]))\n",
    "    #使用Relu激活函数\n",
    "    cur_layer=tf.nn.relu(tf.matmul(cur_layer,weight)+bias)\n",
    "    #进入下一层之前将下一层的节点个数更新为当前节点个数\n",
    "    in_dimension=layer_dimension[i]\n",
    "\n",
    "#在定义神经网络前向传播的同时已经将所有的L2正则化损失加入了图上的集合，\n",
    "#这里只需要计算刻画模型在训练数据上表现的损失函数\n",
    "mse_loss=tf.reduce_mean(tf.square(y_-cur_layer))\n",
    "\n",
    "#将均方误差损失函数加入损失集合\n",
    "tf.add_to_collection('losses',mse_loss)\n",
    "\n",
    "#get_collection返回一个列表，这个列表是所有这个集合中的元素。在这个样例中，\n",
    "#这些元素就是损失函数的不同部分，将它们加起来就可以得到最终的损失函数\n",
    "loss=tf.add_n(tf.get_collection('losses'))\n",
    "train_step=tf.train.AdamOptimizer(0.001).minimize(mse_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(5000):\n",
    "        start=(i*batch_size)%dataset_size\n",
    "        end=min(start+batch_size,dataset_size)\n",
    "#         print('******')\n",
    "#         print(X[start:end],'\\n',Y[start:end])\n",
    "#         print('******')\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81031823]\n",
      " [ 1.4855988 ]]\n",
      "[[-0.8093366]\n",
      " [ 1.4865911]]\n",
      "[[-0.80838311]\n",
      " [ 1.48758912]]\n",
      "[[-0.80742168]\n",
      " [ 1.48854196]]\n",
      "[[-0.80644417]\n",
      " [ 1.4894979 ]]\n",
      "[[-0.80545688]\n",
      " [ 1.49047196]]\n",
      "[[-0.80446237]\n",
      " [ 1.49145281]]\n",
      "[[-0.8034634 ]\n",
      " [ 1.49243844]]\n",
      "[[-0.80245554]\n",
      " [ 1.49342489]]\n",
      "[[-0.80146426]\n",
      " [ 1.49441588]]\n",
      "[[-0.80048096]\n",
      " [ 1.49542165]]\n",
      "[[-0.79950386]\n",
      " [ 1.4964081 ]]\n",
      "[[-0.79850495]\n",
      " [ 1.49741769]]\n",
      "[[-0.79752892]\n",
      " [ 1.49840248]]\n",
      "[[-0.79654419]\n",
      " [ 1.4994123 ]]\n",
      "[[-0.79556257]\n",
      " [ 1.50043571]]\n",
      "[[-0.79462433]\n",
      " [ 1.50143182]]\n",
      "[[-0.79369748]\n",
      " [ 1.50242686]]\n",
      "[[-0.79274493]\n",
      " [ 1.50342429]]\n",
      "[[-0.79180086]\n",
      " [ 1.50438201]]\n",
      "[[-0.79083252]\n",
      " [ 1.50532436]]\n",
      "[[-0.78985554]\n",
      " [ 1.50629151]]\n",
      "[[-0.78887033]\n",
      " [ 1.50725818]]\n",
      "[[-0.78787929]\n",
      " [ 1.50822437]]\n",
      "[[-0.78687394]\n",
      " [ 1.50918674]]\n",
      "[[-0.78588563]\n",
      " [ 1.51015079]]\n",
      "[[-0.78490686]\n",
      " [ 1.51113391]]\n",
      "[[-0.7839362 ]\n",
      " [ 1.51209509]]\n",
      "[[-0.78293514]\n",
      " [ 1.51309192]]\n",
      "[[-0.7819587 ]\n",
      " [ 1.51406181]]\n",
      "[[-0.78097296]\n",
      " [ 1.51506674]]\n",
      "[[-0.77999133]\n",
      " [ 1.51609015]]\n",
      "[[-0.77905494]\n",
      " [ 1.51708424]]\n",
      "[[-0.77813309]\n",
      " [ 1.51807654]]\n",
      "[[-0.77718365]\n",
      " [ 1.51907122]]\n",
      "[[-0.77624506]\n",
      " [ 1.5200237 ]]\n",
      "[[-0.77527946]\n",
      " [ 1.52095795]]\n",
      "[[-0.77430487]\n",
      " [ 1.52191913]]\n",
      "[[-0.77332139]\n",
      " [ 1.52287865]]\n",
      "[[-0.77233142]\n",
      " [ 1.52383661]]\n",
      "[[-0.77132487]\n",
      " [ 1.52478945]]\n",
      "[[-0.77033693]\n",
      " [ 1.52574313]]\n",
      "[[-0.76935965]\n",
      " [ 1.52671778]]\n",
      "[[-0.76839161]\n",
      " [ 1.5276686 ]]\n",
      "[[-0.76738876]\n",
      " [ 1.52865994]]\n",
      "[[-0.7664125 ]\n",
      " [ 1.52962244]]\n",
      "[[-0.76542616]\n",
      " [ 1.53062487]]\n",
      "[[-0.76444453]\n",
      " [ 1.53164828]]\n",
      "[[-0.76351053]\n",
      " [ 1.53264046]]\n",
      "[[-0.76259267]\n",
      " [ 1.53363061]]\n",
      "[[-0.7616455 ]\n",
      " [ 1.53462315]]\n",
      "[[-0.76071036]\n",
      " [ 1.53557146]]\n",
      "[[-0.75974637]\n",
      " [ 1.5365001 ]]\n",
      "[[-0.75877297]\n",
      " [ 1.53745723]]\n",
      "[[-0.75779021]\n",
      " [ 1.53841221]]\n",
      "[[-0.75680059]\n",
      " [ 1.53936517]]\n",
      "[[-0.75579304]\n",
      " [ 1.54031241]]\n",
      "[[-0.75480515]\n",
      " [ 1.54126012]]\n",
      "[[-0.75382864]\n",
      " [ 1.54223001]]\n",
      "[[-0.75286204]\n",
      " [ 1.54317486]]\n",
      "[[-0.75185806]\n",
      " [ 1.54416323]]\n",
      "[[-0.75088191]\n",
      " [ 1.54512143]]\n",
      "[[-0.74989522]\n",
      " [ 1.54612231]]\n",
      "[[-0.74891359]\n",
      " [ 1.54714572]]\n",
      "[[-0.74798131]\n",
      " [ 1.54813671]]\n",
      "[[-0.74706608]\n",
      " [ 1.54912543]]\n",
      "[[-0.74612039]\n",
      " [ 1.55011666]]\n",
      "[[-0.74518746]\n",
      " [ 1.55106211]]\n",
      "[[-0.74422449]\n",
      " [ 1.55198705]]\n",
      "[[-0.7432518 ]\n",
      " [ 1.55294156]]\n",
      "[[-0.74226946]\n",
      " [ 1.55389369]]\n",
      "[[-0.74128002]\n",
      " [ 1.55484354]]\n",
      "[[-0.74027181]\n",
      " [ 1.55578732]]\n",
      "[[-0.73928392]\n",
      " [ 1.55673146]]\n",
      "[[-0.73830789]\n",
      " [ 1.55769837]]\n",
      "[[-0.73734224]\n",
      " [ 1.55863953]]\n",
      "[[-0.73633748]\n",
      " [ 1.55962586]]\n",
      "[[-0.7353614 ]\n",
      " [ 1.56058133]]\n",
      "[[-0.73437452]\n",
      " [ 1.56158125]]\n",
      "[[-0.73339289]\n",
      " [ 1.56260467]]\n",
      "[[-0.73246169]\n",
      " [ 1.56359482]]\n",
      "[[-0.73154819]\n",
      " [ 1.56458259]]\n",
      "[[-0.73060346]\n",
      " [ 1.56557298]]\n",
      "[[-0.72967196]\n",
      " [ 1.56651664]]\n",
      "[[-0.72870964]\n",
      " [ 1.5674392 ]]\n",
      "[[-0.72773743]\n",
      " [ 1.56839192]]\n",
      "[[-0.72675532]\n",
      " [ 1.56934226]]\n",
      "[[-0.72576594]\n",
      " [ 1.57029009]]\n",
      "[[-0.72475725]\n",
      " [ 1.57123148]]\n",
      "[[-0.72377568]\n",
      " [ 1.57215166]]\n",
      "[[-0.72280562]\n",
      " [ 1.57309747]]\n",
      "[[-0.72184557]\n",
      " [ 1.57401896]]\n",
      "[[-0.72084475]\n",
      " [ 1.57498896]]\n",
      "[[-0.71987271]\n",
      " [ 1.57592905]]\n",
      "[[-0.71888918]\n",
      " [ 1.57691646]]\n",
      "[[-0.71791065]\n",
      " [ 1.5779295 ]]\n",
      "[[-0.71698302]\n",
      " [ 1.57890987]]\n",
      "[[-0.71607316]\n",
      " [ 1.57988894]]\n",
      "[[-0.71513128]\n",
      " [ 1.58087158]]\n",
      "[[-0.7142027 ]\n",
      " [ 1.58180761]]\n",
      "[[-0.71324247]\n",
      " [ 1.5827229 ]]\n",
      "[[-0.71227944]\n",
      " [ 1.5836432 ]]\n",
      "[[-0.71130532]\n",
      " [ 1.58456445]]\n",
      "[[-0.71032292]\n",
      " [ 1.58548629]]\n",
      "[[-0.70931995]\n",
      " [ 1.58640444]]\n",
      "[[-0.70835108]\n",
      " [ 1.5872798 ]]\n",
      "[[-0.70739251]\n",
      " [ 1.58818626]]\n",
      "[[-0.70644295]\n",
      " [ 1.58907211]]\n",
      "[[-0.70545053]\n",
      " [ 1.59001172]]\n",
      "[[-0.70448637]\n",
      " [ 1.59092426]]\n",
      "[[-0.70350957]\n",
      " [ 1.59188843]]\n",
      "[[-0.70253706]\n",
      " [ 1.59288168]]\n",
      "[[-0.70161539]\n",
      " [ 1.59384418]]\n",
      "[[-0.70071113]\n",
      " [ 1.59480762]]\n",
      "[[-0.69977379]\n",
      " [ 1.59577668]]\n",
      "[[-0.69884944]\n",
      " [ 1.59670019]]\n",
      "[[-0.69789249]\n",
      " [ 1.59760416]]\n",
      "[[-0.69693232]\n",
      " [ 1.59851456]]\n",
      "[[-0.69596058]\n",
      " [ 1.59942722]]\n",
      "[[-0.69498008]\n",
      " [ 1.60034168]]\n",
      "[[-0.69397837]\n",
      " [ 1.60125327]]\n",
      "[[-0.69301087]\n",
      " [ 1.60212255]]\n",
      "[[-0.69206274]\n",
      " [ 1.60299361]]\n",
      "[[-0.69113004]\n",
      " [ 1.60382175]]\n",
      "[[-0.69015187]\n",
      " [ 1.60471129]]\n",
      "[[-0.68920064]\n",
      " [ 1.60557878]]\n",
      "[[-0.68823516]\n",
      " [ 1.60650432]]\n",
      "[[-0.68727267]\n",
      " [ 1.60746419]]\n",
      "[[-0.68636036]\n",
      " [ 1.60839677]]\n",
      "[[-0.68546462]\n",
      " [ 1.60933399]]\n",
      "[[-0.6845423 ]\n",
      " [ 1.61025572]]\n",
      "[[-0.68363148]\n",
      " [ 1.61113656]]\n",
      "[[-0.68268603]\n",
      " [ 1.61200249]]\n",
      "[[-0.68173593]\n",
      " [ 1.61287951]]\n",
      "[[-0.6807729 ]\n",
      " [ 1.61376274]]\n",
      "[[-0.67979991]\n",
      " [ 1.61465132]]\n",
      "[[-0.67880434]\n",
      " [ 1.61554039]]\n",
      "[[-0.67784822]\n",
      " [ 1.61637008]]\n",
      "[[-0.67691028]\n",
      " [ 1.61720622]]\n",
      "[[-0.67598671]\n",
      " [ 1.61800277]]\n",
      "[[-0.67501593]\n",
      " [ 1.61886561]]\n",
      "[[-0.67407137]\n",
      " [ 1.61970937]]\n",
      "[[-0.67312127]\n",
      " [ 1.6205864 ]]\n",
      "[[-0.67217243]\n",
      " [ 1.62150443]]\n",
      "[[-0.67127252]\n",
      " [ 1.62239981]]\n",
      "[[-0.67038792]\n",
      " [ 1.62330461]]\n",
      "[[-0.66947514]\n",
      " [ 1.62419784]]\n",
      "[[-0.66857278]\n",
      " [ 1.62505329]]\n",
      "[[-0.66763437]\n",
      " [ 1.62589693]]\n",
      "[[-0.66669029]\n",
      " [ 1.62675476]]\n",
      "[[-0.6657322 ]\n",
      " [ 1.62762165]]\n",
      "[[-0.66476327]\n",
      " [ 1.62849653]]\n",
      "[[-0.66377085]\n",
      " [ 1.62937391]]\n",
      "[[-0.6628176 ]\n",
      " [ 1.63019311]]\n",
      "[[-0.66188216]\n",
      " [ 1.63102067]]\n",
      "[[-0.66096073]\n",
      " [ 1.63180959]]\n",
      "[[-0.65999109]\n",
      " [ 1.6326673 ]]\n",
      "[[-0.65904754]\n",
      " [ 1.63350689]]\n",
      "[[-0.65809804]\n",
      " [ 1.63438141]]\n",
      "[[-0.65715867]\n",
      " [ 1.63527036]]\n",
      "[[-0.65626746]\n",
      " [ 1.63614011]]\n",
      "[[-0.65539056]\n",
      " [ 1.63702297]]\n",
      "[[-0.65448427]\n",
      " [ 1.63789713]]\n",
      "[[-0.65358758]\n",
      " [ 1.63873577]]\n",
      "[[-0.65265369]\n",
      " [ 1.63956487]]\n",
      "[[-0.65171337]\n",
      " [ 1.64041078]]\n",
      "[[-0.65075833]\n",
      " [ 1.6412679 ]]\n",
      "[[-0.64979172]\n",
      " [ 1.6421349 ]]\n",
      "[[-0.64880085]\n",
      " [ 1.64300621]]\n",
      "[[-0.64784896]\n",
      " [ 1.64381993]]\n",
      "[[-0.64691466]\n",
      " [ 1.64464331]]\n",
      "[[-0.64599413]\n",
      " [ 1.64542878]]\n",
      "[[-0.6450246 ]\n",
      " [ 1.64628518]]\n",
      "[[-0.64409286]\n",
      " [ 1.64709163]]\n",
      "[[-0.64315367]\n",
      " [ 1.64793777]]\n",
      "[[-0.64222336]\n",
      " [ 1.64880228]]\n",
      "[[-0.64134037]\n",
      " [ 1.64965069]]\n",
      "[[-0.6404708 ]\n",
      " [ 1.65051532]]\n",
      "[[-0.63957059]\n",
      " [ 1.65137386]]\n",
      "[[-0.63867927]\n",
      " [ 1.65219879]]\n",
      "[[-0.63774967]\n",
      " [ 1.65301621]]\n",
      "[[-0.63681293]\n",
      " [ 1.65385258]]\n",
      "[[-0.63586068]\n",
      " [ 1.65470207]]\n",
      "[[-0.63489628]\n",
      " [ 1.65556312]]\n",
      "[[-0.63390684]\n",
      " [ 1.65642989]]\n",
      "[[-0.63295627]\n",
      " [ 1.65723968]]\n",
      "[[-0.63202298]\n",
      " [ 1.65806031]]\n",
      "[[-0.63110322]\n",
      " [ 1.65884364]]\n",
      "[[-0.63013375]\n",
      " [ 1.65969968]]\n",
      "[[-0.62920201]\n",
      " [ 1.66050601]]\n",
      "[[-0.62826252]\n",
      " [ 1.66135323]]\n",
      "[[-0.62733179]\n",
      " [ 1.66221964]]\n",
      "[[-0.62644845]\n",
      " [ 1.66307032]]\n",
      "[[-0.62557846]\n",
      " [ 1.66393793]]\n",
      "[[-0.62467754]\n",
      " [ 1.66479981]]\n",
      "[[-0.62378544]\n",
      " [ 1.66562796]]\n",
      "[[-0.62285465]\n",
      " [ 1.66644895]]\n",
      "[[-0.62191659]\n",
      " [ 1.66728938]]\n",
      "[[-0.62096286]\n",
      " [ 1.66814339]]\n",
      "[[-0.61999679]\n",
      " [ 1.66900933]]\n",
      "[[-0.61900544]\n",
      " [ 1.66988111]]\n",
      "[[-0.61805308]\n",
      " [ 1.67069554]]\n",
      "[[-0.61711812]\n",
      " [ 1.67152119]]\n",
      "[[-0.61619675]\n",
      " [ 1.67230916]]\n",
      "[[-0.61522526]\n",
      " [ 1.6731708 ]]\n",
      "[[-0.61429167]\n",
      " [ 1.67398238]]\n",
      "[[-0.61335027]\n",
      " [ 1.67483532]]\n",
      "[[-0.61242896]\n",
      " [ 1.67567492]]\n",
      "[[-0.61155415]\n",
      " [ 1.67650199]]\n",
      "[[-0.61069173]\n",
      " [ 1.67734933]]\n",
      "[[-0.60979718]\n",
      " [ 1.67819357]]\n",
      "[[-0.60891068]\n",
      " [ 1.67900634]]\n",
      "[[-0.60798448]\n",
      " [ 1.67981398]]\n",
      "[[-0.6070503 ]\n",
      " [ 1.68064332]]\n",
      "[[-0.60609972]\n",
      " [ 1.68148816]]\n",
      "[[-0.60513616]\n",
      " [ 1.6823467 ]]\n",
      "[[-0.60414666]\n",
      " [ 1.68321276]]\n",
      "[[-0.60319591]\n",
      " [ 1.68402207]]\n",
      "[[-0.60226226]\n",
      " [ 1.68484378]]\n",
      "[[-0.6013419 ]\n",
      " [ 1.68562853]]\n",
      "[[-0.60037076]\n",
      " [ 1.68648875]]\n",
      "[[-0.59943748]\n",
      " [ 1.68729925]]\n",
      "[[-0.59849614]\n",
      " [ 1.68815231]]\n",
      "[[-0.59757471]\n",
      " [ 1.6889925 ]]\n",
      "[[-0.59669983]\n",
      " [ 1.68982065]]\n",
      "[[-0.59583724]\n",
      " [ 1.69066989]]\n",
      "[[-0.59494221]\n",
      " [ 1.6915164 ]]\n",
      "[[-0.59405512]\n",
      " [ 1.69233155]]\n",
      "[[-0.59312803]\n",
      " [ 1.69314182]]\n",
      "[[-0.59220558]\n",
      " [ 1.69394112]]\n",
      "[[-0.59126526]\n",
      " [ 1.69475985]]\n",
      "[[-0.59031057]\n",
      " [ 1.69559574]]\n",
      "[[-0.58933228]\n",
      " [ 1.69643259]]\n",
      "[[-0.58839154]\n",
      " [ 1.6972158 ]]\n",
      "[[-0.58746672]\n",
      " [ 1.69801486]]\n",
      "[[-0.58655411]\n",
      " [ 1.69877946]]\n",
      "[[-0.58558941]\n",
      " [ 1.69962335]]\n",
      "[[-0.58466178]\n",
      " [ 1.70041919]]\n",
      "[[-0.58372521]\n",
      " [ 1.70126033]]\n",
      "[[-0.58280796]\n",
      " [ 1.70209038]]\n",
      "[[-0.58193678]\n",
      " [ 1.70290995]]\n",
      "[[-0.58107734]\n",
      " [ 1.7037524 ]]\n",
      "[[-0.58018482]\n",
      " [ 1.70459354]]\n",
      "[[-0.57929981]\n",
      " [ 1.70540416]]\n",
      "[[-0.57837415]\n",
      " [ 1.70621109]]\n",
      "[[-0.57745278]\n",
      " [ 1.70700788]]\n",
      "[[-0.57651305]\n",
      " [ 1.70782518]]\n",
      "[[-0.5755586 ]\n",
      " [ 1.70866072]]\n",
      "[[-0.57458013]\n",
      " [ 1.70949793]]\n",
      "[[-0.57364053]\n",
      " [ 1.71027768]]\n",
      "[[-0.57271653]\n",
      " [ 1.71107447]]\n",
      "[[-0.57180452]\n",
      " [ 1.71183729]]\n",
      "[[-0.57083982]\n",
      " [ 1.71268094]]\n",
      "[[-0.56991214]\n",
      " [ 1.7134769 ]]\n",
      "[[-0.56897521]\n",
      " [ 1.71431923]]\n",
      "[[-0.56805754]\n",
      " [ 1.71515095]]\n",
      "[[-0.56718594]\n",
      " [ 1.71597254]]\n",
      "[[-0.56633562]\n",
      " [ 1.71679342]]\n",
      "[[-0.56545091]\n",
      " [ 1.71761584]]\n",
      "[[-0.56457275]\n",
      " [ 1.71841002]]\n",
      "[[-0.56365281]\n",
      " [ 1.71920276]]\n",
      "[[-0.56273639]\n",
      " [ 1.71998739]]\n",
      "[[-0.56180078]\n",
      " [ 1.72079468]]\n",
      "[[-0.56084973]\n",
      " [ 1.72162199]]\n",
      "[[-0.55987394]\n",
      " [ 1.72245252]]\n",
      "[[-0.55893666]\n",
      " [ 1.72322631]]\n",
      "[[-0.5580219 ]\n",
      " [ 1.72400105]]\n",
      "[[-0.55711806]\n",
      " [ 1.72474444]]\n",
      "[[-0.55616009]\n",
      " [ 1.72557211]]\n",
      "[[-0.55523843]\n",
      " [ 1.72635388]]\n",
      "[[-0.55430663]\n",
      " [ 1.72718465]]\n",
      "[[-0.55339336]\n",
      " [ 1.7280066 ]]\n",
      "[[-0.5525257 ]\n",
      " [ 1.72881997]]\n",
      "[[-0.55167884]\n",
      " [ 1.72963417]]\n",
      "[[-0.55079687]\n",
      " [ 1.73045135]]\n",
      "[[-0.54992098]\n",
      " [ 1.73124111]]\n",
      "[[-0.54900265]\n",
      " [ 1.73203051]]\n",
      "[[-0.54808748]\n",
      " [ 1.73281264]]\n",
      "[[-0.5471527]\n",
      " [ 1.7336185]]\n",
      "[[-0.54620206]\n",
      " [ 1.73444545]]\n",
      "[[-0.54522628]\n",
      " [ 1.73527634]]\n",
      "[[-0.54428887]\n",
      " [ 1.73605061]]\n",
      "[[-0.54337394]\n",
      " [ 1.73682642]]\n",
      "[[-0.54246974]\n",
      " [ 1.737571  ]]\n",
      "[[-0.541511  ]\n",
      " [ 1.73840129]]\n",
      "[[-0.5405885 ]\n",
      " [ 1.73918557]]\n",
      "[[-0.53965569]\n",
      " [ 1.74001968]]\n",
      "[[-0.53874135]\n",
      " [ 1.7408452 ]]\n",
      "[[-0.53787267]\n",
      " [ 1.74166238]]\n",
      "[[-0.5370248 ]\n",
      " [ 1.74248064]]\n",
      "[[-0.53614157]\n",
      " [ 1.74330211]]\n",
      "[[-0.53526437]\n",
      " [ 1.74409616]]\n",
      "[[-0.53434455]\n",
      " [ 1.74488997]]\n",
      "[[-0.53342783]\n",
      " [ 1.74567664]]\n",
      "[[-0.53249133]\n",
      " [ 1.74648738]]\n",
      "[[-0.5315389 ]\n",
      " [ 1.74731946]]\n",
      "[[-0.53056115]\n",
      " [ 1.74815559]]\n",
      "[[-0.5296219 ]\n",
      " [ 1.74893475]]\n",
      "[[-0.52870518]\n",
      " [ 1.74971557]]\n",
      "[[-0.52779919]\n",
      " [ 1.75046492]]\n",
      "[[-0.52683842]\n",
      " [ 1.75130069]]\n",
      "[[-0.52591401]\n",
      " [ 1.75209022]]\n",
      "[[-0.52497923]\n",
      " [ 1.75293005]]\n",
      "[[-0.52406299]\n",
      " [ 1.75376117]]\n",
      "[[-0.52319258]\n",
      " [ 1.75458384]]\n",
      "[[-0.52234304]\n",
      " [ 1.75540769]]\n",
      "[[-0.52145803]\n",
      " [ 1.75623477]]\n",
      "[[-0.5205791 ]\n",
      " [ 1.75703418]]\n",
      "[[-0.51965731]\n",
      " [ 1.75783336]]\n",
      "[[-0.51873869]\n",
      " [ 1.75862539]]\n",
      "[[-0.51780021]\n",
      " [ 1.75944161]]\n",
      "[[-0.5168457 ]\n",
      " [ 1.76027942]]\n",
      "[[-0.5158658 ]\n",
      " [ 1.76112127]]\n",
      "[[-0.51492459]\n",
      " [ 1.76190579]]\n",
      "[[-0.51400596]\n",
      " [ 1.76269186]]\n",
      "[[-0.51309812]\n",
      " [ 1.76344621]]\n",
      "[[-0.51213527]\n",
      " [ 1.76428771]]\n",
      "[[-0.51120889]\n",
      " [ 1.7650826 ]]\n",
      "[[-0.51027215]\n",
      " [ 1.76592815]]\n",
      "[[-0.509354  ]\n",
      " [ 1.76676488]]\n",
      "[[-0.50848186]\n",
      " [ 1.76759315]]\n",
      "[[-0.50763065]\n",
      " [ 1.76842248]]\n",
      "[[-0.50674385]\n",
      " [ 1.76925504]]\n",
      "[[-0.50586319]\n",
      " [ 1.7700597 ]]\n",
      "[[-0.50493956]\n",
      " [ 1.77086413]]\n",
      "[[-0.50401908]\n",
      " [ 1.77166128]]\n",
      "[[-0.5030787 ]\n",
      " [ 1.77248287]]\n",
      "[[-0.50212228]\n",
      " [ 1.77332604]]\n",
      "[[-0.50114036]\n",
      " [ 1.77417338]]\n",
      "[[-0.50019723]\n",
      " [ 1.7749629 ]]\n",
      "[[-0.49927679]\n",
      " [ 1.77575397]]\n",
      "[[-0.49836719]\n",
      " [ 1.7765131 ]]\n",
      "[[-0.49740243]\n",
      " [ 1.77735996]]\n",
      "[[-0.49647427]\n",
      " [ 1.77815986]]\n",
      "[[-0.4955357 ]\n",
      " [ 1.77901077]]\n",
      "[[-0.49461582]\n",
      " [ 1.77985275]]\n",
      "[[-0.49374208]\n",
      " [ 1.78068614]]\n",
      "[[-0.49288931]\n",
      " [ 1.78152061]]\n",
      "[[-0.49200091]\n",
      " [ 1.78235829]]\n",
      "[[-0.49111864]\n",
      " [ 1.78316796]]\n",
      "[[-0.49019331]\n",
      " [ 1.78397727]]\n",
      "[[-0.48927113]\n",
      " [ 1.78477919]]\n",
      "[[-0.48832902]\n",
      " [ 1.78560567]]\n",
      "[[-0.48737085]\n",
      " [ 1.78645396]]\n",
      "[[-0.4863871 ]\n",
      " [ 1.78730631]]\n",
      "[[-0.48544228]\n",
      " [ 1.78810048]]\n",
      "[[-0.4845202]\n",
      " [ 1.7888962]]\n",
      "[[-0.48360899]\n",
      " [ 1.78965974]]\n",
      "[[-0.48264244]\n",
      " [ 1.79051161]]\n",
      "[[-0.48171264]\n",
      " [ 1.79131615]]\n",
      "[[-0.48078582]\n",
      " [ 1.79214251]]\n",
      "[[-0.47987637]\n",
      " [ 1.79296291]]\n",
      "[[-0.47901195]\n",
      " [ 1.79377735]]\n",
      "[[-0.4781675 ]\n",
      " [ 1.79459536]]\n",
      "[[-0.47728631]\n",
      " [ 1.79541886]]\n",
      "[[-0.47641036]\n",
      " [ 1.79621601]]\n",
      "[[-0.47549042]\n",
      " [ 1.79701459]]\n",
      "[[-0.47457293]\n",
      " [ 1.79780734]]\n",
      "[[-0.47363478]\n",
      " [ 1.7986263 ]]\n",
      "[[-0.47267991]\n",
      " [ 1.7994684 ]]\n",
      "[[-0.47169888]\n",
      " [ 1.80031574]]\n",
      "[[-0.47075641]\n",
      " [ 1.8011055 ]]\n",
      "[[-0.46983632]\n",
      " [ 1.80189776]]\n",
      "[[-0.46892676]\n",
      " [ 1.80265856]]\n",
      "[[-0.46796134]\n",
      " [ 1.803509  ]]\n",
      "[[-0.46703246]\n",
      " [ 1.80431247]]\n",
      "[[-0.4661063 ]\n",
      " [ 1.80513859]]\n",
      "[[-0.46519732]\n",
      " [ 1.80595922]]\n",
      "[[-0.4643333 ]\n",
      " [ 1.80677438]]\n",
      "[[-0.46348909]\n",
      " [ 1.80759346]]\n",
      "[[-0.46260786]\n",
      " [ 1.80841839]]\n",
      "[[-0.46173176]\n",
      " [ 1.80921721]]\n",
      "[[-0.46081138]\n",
      " [ 1.81001782]]\n",
      "[[-0.45989332]\n",
      " [ 1.81081283]]\n",
      "[[-0.45895445]\n",
      " [ 1.81163442]]\n",
      "[[-0.45799872]\n",
      " [ 1.81247962]]\n",
      "[[-0.45701665]\n",
      " [ 1.81333029]]\n",
      "[[-0.45607316]\n",
      " [ 1.81412315]]\n",
      "[[-0.45515203]\n",
      " [ 1.81491864]]\n",
      "[[-0.45424142]\n",
      " [ 1.81568253]]\n",
      "[[-0.45327473]\n",
      " [ 1.8165369 ]]\n",
      "[[-0.45234463]\n",
      " [ 1.81734407]]\n",
      "[[-0.45141721]\n",
      " [ 1.81817412]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45050699]\n",
      " [ 1.81899869]]\n",
      "[[-0.44964769]\n",
      " [ 1.81980479]]\n",
      "[[-0.44880766]\n",
      " [ 1.82061625]]\n",
      "[[-0.44792995]\n",
      " [ 1.82143486]]\n",
      "[[-0.44705686]\n",
      " [ 1.82222831]]\n",
      "[[-0.44613892]\n",
      " [ 1.82302451]]\n",
      "[[-0.44522291]\n",
      " [ 1.82381594]]\n",
      "[[-0.44428566]\n",
      " [ 1.82463503]]\n",
      "[[-0.44333118]\n",
      " [ 1.82547855]]\n",
      "[[-0.44235182]\n",
      " [ 1.82632375]]\n",
      "[[-0.44141069]\n",
      " [ 1.82711172]]\n",
      "[[-0.44049159]\n",
      " [ 1.82790339]]\n",
      "[[-0.43958265]\n",
      " [ 1.82866406]]\n",
      "[[-0.43861714]\n",
      " [ 1.82951653]]\n",
      "[[-0.43768802]\n",
      " [ 1.83032227]]\n",
      "[[-0.43676132]\n",
      " [ 1.8311516 ]]\n",
      "[[-0.43585163]\n",
      " [ 1.83197606]]\n",
      "[[-0.43499279]\n",
      " [ 1.83278239]]\n",
      "[[-0.43415305]\n",
      " [ 1.83359456]]\n",
      "[[-0.43327537]\n",
      " [ 1.83441424]]\n",
      "[[-0.43240219]\n",
      " [ 1.83520889]]\n",
      "[[-0.43148389]\n",
      " [ 1.83600676]]\n",
      "[[-0.43056744]\n",
      " [ 1.8368001 ]]\n",
      "[[-0.42962956]\n",
      " [ 1.83762145]]\n",
      "[[-0.42867431]\n",
      " [ 1.8384676 ]]\n",
      "[[-0.42769402]\n",
      " [ 1.83931565]]\n",
      "[[-0.426752  ]\n",
      " [ 1.84010637]]\n",
      "[[-0.42583197]\n",
      " [ 1.8409009 ]]\n",
      "[[-0.42493862]\n",
      " [ 1.84162879]]\n",
      "[[-0.42398676]\n",
      " [ 1.84245288]]\n",
      "[[-0.42306983]\n",
      " [ 1.84323323]]\n",
      "[[-0.42215395]\n",
      " [ 1.84404027]]\n",
      "[[-0.42125386]\n",
      " [ 1.84484506]]\n",
      "[[-0.42041692]\n",
      " [ 1.84560645]]\n",
      "[[-0.41959682]\n",
      " [ 1.84637868]]\n",
      "[[-0.41873652]\n",
      " [ 1.84716296]]\n",
      "[[-0.41787884]\n",
      " [ 1.84792602]]\n",
      "[[-0.41697416]\n",
      " [ 1.84869587]]\n",
      "[[-0.41606978]\n",
      " [ 1.84946442]]\n",
      "[[-0.41515273]\n",
      " [ 1.85024416]]\n",
      "[[-0.41421592]\n",
      " [ 1.8510536 ]]\n",
      "[[-0.41325191]\n",
      " [ 1.85186911]]\n",
      "[[-0.41232443]\n",
      " [ 1.85263062]]\n",
      "[[-0.41141737]\n",
      " [ 1.8533994 ]]\n",
      "[[-0.41053557]\n",
      " [ 1.85410404]]\n",
      "[[-0.40959367]\n",
      " [ 1.85490859]]\n",
      "[[-0.40868559]\n",
      " [ 1.85567141]]\n",
      "[[-0.40777746]\n",
      " [ 1.85646343]]\n",
      "[[-0.40688419]\n",
      " [ 1.85725522]]\n",
      "[[-0.40605339]\n",
      " [ 1.85800505]]\n",
      "[[-0.40523869]\n",
      " [ 1.85876739]]\n",
      "[[-0.40438294]\n",
      " [ 1.85954332]]\n",
      "[[-0.40352917]\n",
      " [ 1.86029923]]\n",
      "[[-0.40262768]\n",
      " [ 1.86106312]]\n",
      "[[-0.40172598]\n",
      " [ 1.86182678]]\n",
      "[[-0.40081111]\n",
      " [ 1.86260259]]\n",
      "[[-0.399876  ]\n",
      " [ 1.86340916]]\n",
      "[[-0.39893156]\n",
      " [ 1.86418521]]\n",
      "[[-0.39802155]\n",
      " [ 1.86491132]]\n",
      "[[-0.39713004]\n",
      " [ 1.86564875]]\n",
      "[[-0.39626208]\n",
      " [ 1.86632526]]\n",
      "[[-0.39533216]\n",
      " [ 1.86710572]]\n",
      "[[-0.39443475]\n",
      " [ 1.86784708]]\n",
      "[[-0.39353597]\n",
      " [ 1.86862051]]\n",
      "[[-0.39265093]\n",
      " [ 1.86939609]]\n",
      "[[-0.39182749]\n",
      " [ 1.87013149]]\n",
      "[[-0.39101925]\n",
      " [ 1.87088144]]\n",
      "[[-0.39016899]\n",
      " [ 1.87164688]]\n",
      "[[-0.38931996]\n",
      " [ 1.87239361]]\n",
      "[[-0.38842234]\n",
      " [ 1.87314987]]\n",
      "[[-0.38752386]\n",
      " [ 1.87390709]]\n",
      "[[-0.38661164]\n",
      " [ 1.87467766]]\n",
      "[[-0.38567862]\n",
      " [ 1.87548029]]\n",
      "[[-0.38473576]\n",
      " [ 1.87625301]]\n",
      "[[-0.38382706]\n",
      " [ 1.87697637]]\n",
      "[[-0.38293654]\n",
      " [ 1.87771177]]\n",
      "[[-0.38206932]\n",
      " [ 1.8783865 ]]\n",
      "[[-0.38113964]\n",
      " [ 1.87916648]]\n",
      "[[-0.38024229]\n",
      " [ 1.87990773]]\n",
      "[[-0.37936184]\n",
      " [ 1.88064754]]\n",
      "[[-0.3784931 ]\n",
      " [ 1.88139343]]\n",
      "[[-0.3776843 ]\n",
      " [ 1.88210237]]\n",
      "[[-0.37688905]\n",
      " [ 1.88282907]]\n",
      "[[-0.37605011]\n",
      " [ 1.88357425]]\n",
      "[[-0.37521103]\n",
      " [ 1.88430309]]\n",
      "[[-0.37432194]\n",
      " [ 1.88504386]]\n",
      "[[-0.37343091]\n",
      " [ 1.88578761]]\n",
      "[[-0.37252507]\n",
      " [ 1.88654673]]\n",
      "[[-0.37159744]\n",
      " [ 1.88733971]]\n",
      "[[-0.37065914]\n",
      " [ 1.8881042 ]]\n",
      "[[-0.3697544 ]\n",
      " [ 1.88882017]]\n",
      "[[-0.36886725]\n",
      " [ 1.88954961]]\n",
      "[[-0.36800289]\n",
      " [ 1.89021897]]\n",
      "[[-0.36709467]\n",
      " [ 1.89095879]]\n",
      "[[-0.36622211]\n",
      " [ 1.89165103]]\n",
      "[[-0.36536372]\n",
      " [ 1.89234734]]\n",
      "[[-0.36451459]\n",
      " [ 1.89305472]]\n",
      "[[-0.36373699]\n",
      " [ 1.89370203]]\n",
      "[[-0.36297414]\n",
      " [ 1.89436626]]\n",
      "[[-0.36216384]\n",
      " [ 1.89505589]]\n",
      "[[-0.36135027]\n",
      " [ 1.89573526]]\n",
      "[[-0.36048362]\n",
      " [ 1.89643216]]\n",
      "[[-0.35961244]\n",
      " [ 1.89713705]]\n",
      "[[-0.35872406]\n",
      " [ 1.89786196]]\n",
      "[[-0.35781175]\n",
      " [ 1.89862514]]\n",
      "[[-0.35688686]\n",
      " [ 1.89936316]]\n",
      "[[-0.35599399]\n",
      " [ 1.90005553]]\n",
      "[[-0.35511729]\n",
      " [ 1.90076435]]\n",
      "[[-0.35426211]\n",
      " [ 1.90141535]]\n",
      "[[-0.35336167]\n",
      " [ 1.90213978]]\n",
      "[[-0.35249594]\n",
      " [ 1.90281832]]\n",
      "[[-0.35164344]\n",
      " [ 1.90350294]]\n",
      "[[-0.35079935]\n",
      " [ 1.90420043]]\n",
      "[[-0.35002628]\n",
      " [ 1.9048388 ]]\n",
      "[[-0.3492673 ]\n",
      " [ 1.90549564]]\n",
      "[[-0.34846005]\n",
      " [ 1.90617943]]\n",
      "[[-0.34764892]\n",
      " [ 1.90685403]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "#两个输入节点,回归问题一般只有\n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name=\"x-input\")\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name=\"y-input\")\n",
    "#定义一个单层的神经网络前向传播的过程，这里是简单的加权和\n",
    "w1=tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y=tf.matmul(x,w1)\n",
    "#定义预测多了和预测少了的成本\n",
    "loss_less=10\n",
    "loss_more=1\n",
    "loss=tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_)*loss_more,(y_-y)*loss_less))\n",
    "train_step=tf.train.AdamOptimizer(0.001).minimize(loss) #优化器\n",
    "\n",
    "#通过随机数生成一个模拟数据集\n",
    "rdm=RandomState(1)\n",
    "dataset_size=128\n",
    "X=rdm.rand(dataset_size,2)\n",
    "\n",
    "#设置回归的正确值为两个输入的和加上一个随机量。加上随机量是为了加入不可预测的噪音，否则不同损失函数的意义就不大了\n",
    "#因为不同损失函数都会在能完全预测正确的时候最低。一般来说，噪音为一个均值为0的小量，所以这里噪声设置为-0.05~0.05的随机数\n",
    "Y=[[x1+x2+rdm.rand()/10.0-0.05] for (x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(500):\n",
    "        start=(i*batch_size)%dataset_size\n",
    "        end=min(start+batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
