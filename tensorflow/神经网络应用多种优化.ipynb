{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标：简单的神经网络\n",
    "# 保存网络\n",
    "# 读取数据，验证集测试模型\n",
    "# 加入指数衰减\n",
    "# 梯度下降\n",
    "# L2正则\n",
    "# 滑动平均模型\n",
    "# dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784) (100, 10)\n",
      "0.75 ----------- 1.10251\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "\n",
    "#初始化权重\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "# 再加一层卷积\n",
    "\n",
    "weights_4=init_weight([3,3,1,64])\n",
    "bias=init_bias([64])\n",
    "layer4_conv=tf.nn.relu(con2d(x_,weights_4,[1,1,1,1],'SAME')+bias)\n",
    "#全连接\n",
    "\n",
    "node_nums=layer4_conv.get_shape().as_list()\n",
    "weight_3=init_weight([node_nums[1]*node_nums[2]*node_nums[3],10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer4_conv,[-1,node_nums[1]*node_nums[2]*node_nums[3]])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    print(xs.shape,ys.shape)\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_step,correct,cross_entropy],feed_dict={x:xs,y_:ys})\n",
    "    print(correct_,'-----------',cross_entropy_)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784) (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "MODEL_PATH='CONV_Mnist'\n",
    "MODEL_NAME='model.ckpt'\n",
    "#初始化权重\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "node_nums=layer2_pool.get_shape().as_list()\n",
    "weight_3=init_weight([node_nums[1]*node_nums[2]*node_nums[3],10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer2_pool,[-1,node_nums[1]*node_nums[2]*node_nums[3]])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    print(xs.shape,ys.shape)\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_step,correct,cross_entropy],feed_dict={x:xs,y_:ys})\n",
    "        if cross_entropy_ < 2.4:\n",
    "            saver.save(sess,os.path.join(MODEL_PATH,MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# L2正则化\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "L2_REGULARIZER=0.01\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "MODEL_PATH='CONV_Mnist'\n",
    "MODEL_NAME='model.ckpt'\n",
    "#初始化权重\n",
    "weightList=[]\n",
    "# 防止变量名重复\n",
    "tf.reset_default_graph()\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))    \n",
    "    weightList.append(tf.nn.l2_loss(weights))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "# 全连接 fcn\n",
    "weight_3=init_weight([140*140*32,10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer2_pool,[-1,140*140*32])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "\n",
    "loss=tf.add_n(weightList)+cross_entropy\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "   \n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_step,correct,cross_entropy],feed_dict={x:xs,y_:ys})        \n",
    "        if i == 200:\n",
    "            saver.save(sess,os.path.join(MODEL_PATH,MODEL_NAME))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from CONV_Mnist/model.ckpt\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "#读取模型\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "L2_REGULARIZER=0.01\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "MODEL_PATH='CONV_Mnist'\n",
    "MODEL_NAME='model.ckpt'\n",
    "#初始化权重\n",
    "weightList=[]\n",
    "tf.reset_default_graph()\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))    \n",
    "    weightList.append(tf.nn.l2_loss(weights))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "# 全连接 fcn\n",
    "weight_3=init_weight([140*140*32,10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer2_pool,[-1,140*140*32])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "\n",
    "loss=tf.add_n(weightList)+cross_entropy\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    saver.restore(sess,'CONV_Mnist/model.ckpt')\n",
    "    correct_=sess.run(correct,feed_dict={x:xs,y_:ys})\n",
    "    print(correct_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784) (100, 10)\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "# 指数衰减\n",
    "# 保存模型\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "\n",
    "LEARNING_RATE=0.001\n",
    "LEARNING_BASE=0.01\n",
    "LEARN_DECAY=0.96\n",
    "\n",
    "TRAINING_STEPS=300\n",
    "MODEL_PATH='CONV_Mnist'\n",
    "MODEL_NAME='model.ckpt'\n",
    "#初始化权重\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "\n",
    "weight_3=init_weight([140*140*32,10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer2_pool,[-1,140*140*32])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "global_step=tf.Variable(0,trainable=False)\n",
    "#设置学习率\n",
    "learning_rate=tf.train.exponential_decay(LEARNING_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARN_DECAY)\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy,global_step=global_step)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    print(xs.shape,ys.shape)\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_step,correct,cross_entropy],feed_dict={x:xs,y_:ys})\n",
    "    print(correct_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784) (100, 10)\n",
      "0.14\n"
     ]
    }
   ],
   "source": [
    "# 滑动均值\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "MODEL_PATH='CONV_Mnist'\n",
    "MODEL_NAME='model.ckpt'\n",
    "\n",
    "MOVING_DACAY=0.99\n",
    "#初始化权重\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 #28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "\n",
    "weight_3=init_weight([140*140*32,10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer2_pool,[-1,140*140*32])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "gloal_step=tf.Variable(0,trainable=False)\n",
    "ema=tf.train.ExponentialMovingAverage(MOVING_DACAY,gloal_step)\n",
    "ema_op=ema.apply(tf.trainable_variables())\n",
    "\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy,global_step=gloal_step)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.control_dependencies([ema_op,train_step]):\n",
    "    train_op=tf.no_op(name='train')\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    print(xs.shape,ys.shape)\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_op,correct,cross_entropy],feed_dict={x:xs,y_:ys})\n",
    "    print(correct_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784) (100, 10)\n",
      "0.69 ----------- 1.07192\n"
     ]
    }
   ],
   "source": [
    "#使用dropout防止过拟合\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "BATCH_SIZE=100\n",
    "INPUT=784\n",
    "OUTPUT=10\n",
    "NUM_CHANNELS=1\n",
    "IMAGE=28\n",
    "LEARNING_RATE=0.001\n",
    "TRAINING_STEPS=300\n",
    "\n",
    "#初始化权重\n",
    "def init_weight(shape):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return weights\n",
    "\n",
    "#初始化偏执\n",
    "def init_bias(shape):\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return bias\n",
    "\n",
    "#卷积层封装\n",
    "def con2d(x,weights,strides,padding_type):\n",
    "    return tf.nn.conv2d(x,weights,strides=strides,padding=padding_type)\n",
    "\n",
    "#池化层\n",
    "def pooling(x,kernel,strides,padding_type):\n",
    "    return tf.nn.max_pool(x,ksize=kernel,strides=strides,padding=padding_type)\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,INPUT],name='x')\n",
    "y_=tf.placeholder(tf.float32,shape=[None,OUTPUT],name='y')\n",
    "x_=tf.reshape(x,[-1,IMAGE,IMAGE,NUM_CHANNELS])\n",
    "\n",
    "#卷积 # 第一层p=(f-1)/2=2 n+2p-f+1=28+2*2-5+1=28\n",
    "weights_1=init_weight([5,5,1,32])\n",
    "bias=init_bias([32])\n",
    "layer1_conv=tf.nn.relu(con2d(x_,weights_1,[1,1,1,1],'SAME')+bias)\n",
    "\n",
    "#池化 # 第二层p=(f-1)/2=1 n+2p-f+1=26+2*(1/2)-2+1=26  ==>28\n",
    "layer2_pool=pooling(layer1_conv,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "# 再加一层卷积\n",
    "weights_4=init_weight([3,3,1,64])\n",
    "bias=init_bias([64])\n",
    "layer4_conv=tf.nn.relu(con2d(x_,weights_4,[1,1,1,1],'SAME')+bias)\n",
    "tf.nn.dropout(layer4_conv,0.8)\n",
    "#全连接\n",
    "\n",
    "node_nums=layer4_conv.get_shape().as_list()\n",
    "weight_3=init_weight([node_nums[1]*node_nums[2]*node_nums[3],10])\n",
    "bias_3=init_bias([10])\n",
    "layer2_pool=tf.reshape(layer4_conv,[-1,node_nums[1]*node_nums[2]*node_nums[3]])\n",
    "y=tf.nn.softmax(tf.matmul(layer2_pool,weight_3)+bias_3)\n",
    "\n",
    "# 设置损失函数\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "correct=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "    print(xs.shape,ys.shape)\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        _,correct_,cross_entropy_=sess.run([train_step,correct,cross_entropy],feed_dict={x:xs,y_:ys})\n",
    "    print(correct_,'-----------',cross_entropy_)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
