{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2020-01-01       NaN       NaN       NaN       NaN\n",
      "2020-01-02       NaN       NaN       NaN       NaN\n",
      "2020-01-03 -0.339891  0.539835 -0.008091 -0.390416\n",
      "2020-01-04 -0.562085  0.293806 -0.793714 -0.344571\n",
      "2020-01-05 -0.654160  1.015635 -0.463746 -0.670590\n",
      "2020-01-06 -0.660995  0.076085  0.448617 -0.636215\n",
      "2020-01-07  0.105418 -0.738326  1.156159 -0.935014\n",
      "2020-01-08 -0.162251 -0.751292  0.173817 -0.357349\n",
      "2020-01-09 -0.352836 -0.806104 -0.632360 -0.084470\n",
      "2020-01-10 -0.727505 -0.469329 -1.372717  0.054720\n"
     ]
    }
   ],
   "source": [
    "# 为了处理数字数据，Pandas提供了几个变体，如滚动，展开和指数移动窗口统计的权重。 \n",
    "# 其中包括总和，均值，中位数，方差，协方差，相关性等。\n",
    "# 下来学习如何在DataFrame对象上应用上提及的每种方法。\n",
    "df=pd.DataFrame(np.random.randn(10,4),\n",
    "                 index=pd.date_range('1/1/2020',periods=10),\n",
    "                 columns=['A','B','C','D'])\n",
    "print(df.rolling(window=3).mean())\n",
    "\n",
    "# 注 - 由于窗口大小为3(window)，前两个元素有空值，\n",
    "# 第三个元素的值将是n，n-1和n-2元素的平均值。\n",
    "# 这样也可以应用上面提到的各种函数了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2020-01-01       NaN       NaN       NaN       NaN\n",
      "2020-01-02       NaN       NaN       NaN       NaN\n",
      "2020-01-03       NaN       NaN       NaN       NaN\n",
      "2020-01-04 -0.526990  0.583497 -0.163105 -0.373667\n",
      "2020-01-05 -0.426879  0.594763 -0.014976 -0.696951\n",
      "2020-01-06 -0.500443  0.307960  0.220263 -0.513315\n",
      "2020-01-07 -0.255958  0.017002  0.402294 -0.614244\n",
      "2020-01-08 -0.327643  0.089993  0.055821 -0.569600\n",
      "2020-01-09 -0.451241 -0.063394 -0.063945 -0.370367\n",
      "2020-01-10 -0.397422 -0.128898 -0.130209 -0.413555\n"
     ]
    }
   ],
   "source": [
    "# .expanding()函数\n",
    "# 这个函数可以应用于一系列数据。 \n",
    "# 指定min_periods = n参数并在其上应用适当的统计函数。\n",
    "print(df.expanding(min_periods=4).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2020-01-01 -0.421704  1.452569  1.728723 -0.460953\n",
      "2020-01-02  0.081916 -0.781102  0.122905 -0.874262\n",
      "2020-01-03 -0.561705  0.931458 -0.890311 -0.060108\n",
      "2020-01-04 -0.917148  0.784999 -0.713349 -0.237844\n",
      "2020-01-05 -0.320884  0.687819  0.150799 -1.410833\n",
      "2020-01-06 -0.686305 -0.523091  0.982378 -0.198707\n",
      "2020-01-07  0.579111 -1.327233  1.323937 -0.879758\n",
      "2020-01-08 -0.360067 -0.041595 -1.138722 -0.464583\n",
      "2020-01-09 -1.080072 -0.874234 -1.060953  0.660861\n",
      "2020-01-10 -0.302048 -0.770361 -0.838040 -0.314561\n"
     ]
    }
   ],
   "source": [
    "# .ewm()函数\n",
    "# ewm()可应用于系列数据。指定com，span，halflife参数，并在其上应用适当的统计函数。\n",
    "# 它以指数形式分配权重。\n",
    "print(df.ewm(com=0.5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 窗口函数主要用于通过平滑曲线来以图形方式查找数据内的趋势。\n",
    "# 如果日常数据中有很多变化，并且有很多数据点可用，\n",
    "# 那么采样和绘图就是一种方法，应用窗口计算并在结果上绘制图形是另一种方法。\n",
    "# 通过这些方法，可以平滑曲线或趋势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2019-01-01  0.499927  1.407370 -0.196357 -0.484357\n",
      "2019-01-02  0.695857 -1.054983 -1.417943  0.082760\n",
      "2019-01-03 -0.282634 -0.179371 -0.623492 -0.391143\n",
      "2019-01-04 -0.130631  0.340901  0.356832 -1.348395\n",
      "2019-01-05 -0.188167 -0.421423  0.548559  0.891733\n",
      "2019-01-06  0.468410 -0.800662 -0.891517  0.113252\n",
      "2019-01-07  0.754976  0.641301  0.040835 -0.075243\n",
      "2019-01-08  1.124826 -0.758490  0.199214 -0.415110\n",
      "2019-01-09 -1.653149 -0.657416  0.016465 -1.342704\n",
      "2019-01-10  0.723923 -1.664042  1.453066 -0.585034\n",
      "===========================================================================\n",
      "Rolling [window=3,min_periods=1,center=False,axis=0]\n"
     ]
    }
   ],
   "source": [
    "# 当有了滚动，扩展和ewm对象创建了以后，就有几种方法可以对数据执行聚合。\n",
    "# DataFrame应用聚合\n",
    "# 让我们创建一个DataFrame并在其上应用聚合。\n",
    "df=pd.DataFrame(np.random.randn(10,4),\n",
    "               index=pd.date_range('1/1/2019',periods=10),\n",
    "               columns=['A','B','C','D'])\n",
    "print(df)\n",
    "print('====='*15)\n",
    "r=df.rolling(window=3,min_periods=1)\n",
    "print(r)\n",
    "\n",
    "# 可以通过向整个DataFrame传递一个函数来进行聚合，或者通过标准的获取项目方法来选择一个列。\n",
    "# 在整个数据框上应用聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2019-01-01  1.096083 -0.781778  0.548079  2.081662\n",
      "2019-01-02 -0.780506 -0.962295  0.281837 -2.223401\n",
      "2019-01-03  0.312485  0.619162  0.106385 -1.261635\n",
      "2019-01-04  0.077983 -0.275639  0.460522 -0.992262\n",
      "2019-01-05 -0.058453 -0.034048 -0.997738  0.625856\n",
      "2019-01-06  0.113821  1.042480  0.182223  0.512576\n",
      "2019-01-07 -2.241711  0.279337 -0.417051 -1.240365\n",
      "2019-01-08  1.372465  0.361526  1.147639  0.188681\n",
      "2019-01-09 -0.630546  1.081823 -1.686024 -1.128149\n",
      "2019-01-10 -0.501908 -0.011127  0.811655 -1.521394\n",
      "                   A         B         C         D\n",
      "2019-01-01  1.096083 -0.781778  0.548079  2.081662\n",
      "2019-01-02  0.315577 -1.744073  0.829916 -0.141739\n",
      "2019-01-03  0.628062 -1.124912  0.936301 -1.403374\n",
      "2019-01-04 -0.390038 -0.618772  0.848744 -4.477298\n",
      "2019-01-05  0.332015  0.309475 -0.430831 -1.628041\n",
      "2019-01-06  0.133351  0.732793 -0.354992  0.146170\n",
      "2019-01-07 -2.186343  1.287769 -1.232565 -0.101933\n",
      "2019-01-08 -0.755425  1.683343  0.912811 -0.539107\n",
      "2019-01-09 -1.499792  1.722685 -0.955436 -2.179832\n",
      "2019-01-10  0.240011  1.432221  0.273269 -2.460861\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(np.random.randn(10,4),\n",
    "               index=pd.date_range('1/1/2019',periods=10),\n",
    "               columns=['A','B','C','D'])\n",
    "print(df)\n",
    "r=df.rolling(window=3,min_periods=1)\n",
    "print(r.aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01    1.096083\n",
      "2019-01-02    0.315577\n",
      "2019-01-03    0.628062\n",
      "2019-01-04   -0.390038\n",
      "2019-01-05    0.332015\n",
      "2019-01-06    0.133351\n",
      "2019-01-07   -2.186343\n",
      "2019-01-08   -0.755425\n",
      "2019-01-09   -1.499792\n",
      "2019-01-10    0.240011\n",
      "Freq: D, Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 在数据框的单个列上应用聚合\n",
    "print(r['A'].aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B\n",
      "                 sum       sum\n",
      "2019-01-01  1.096083 -0.781778\n",
      "2019-01-02  0.315577 -1.744073\n",
      "2019-01-03  0.628062 -1.124912\n",
      "2019-01-04 -0.390038 -0.618772\n",
      "2019-01-05  0.332015  0.309475\n",
      "2019-01-06  0.133351  0.732793\n",
      "2019-01-07 -2.186343  1.287769\n",
      "2019-01-08 -0.755425  1.683343\n",
      "2019-01-09 -1.499792  1.722685\n",
      "2019-01-10  0.240011  1.432221\n"
     ]
    }
   ],
   "source": [
    "# 在DataFrame的多列上应用聚合\n",
    "print(r[['A','B']].aggregate([np.sum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum      mean\n",
      "2019-01-01  1.096083  1.096083\n",
      "2019-01-02  0.315577  0.157789\n",
      "2019-01-03  0.628062  0.209354\n",
      "2019-01-04 -0.390038 -0.130013\n",
      "2019-01-05  0.332015  0.110672\n",
      "2019-01-06  0.133351  0.044450\n",
      "2019-01-07 -2.186343 -0.728781\n",
      "2019-01-08 -0.755425 -0.251808\n",
      "2019-01-09 -1.499792 -0.499931\n",
      "2019-01-10  0.240011  0.080004\n"
     ]
    }
   ],
   "source": [
    "print(r['A'].aggregate([np.sum,np.mean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A                   B          \n",
      "                 sum      mean       sum      mean\n",
      "2019-01-01  1.096083  1.096083 -0.781778 -0.781778\n",
      "2019-01-02  0.315577  0.157789 -1.744073 -0.872037\n",
      "2019-01-03  0.628062  0.209354 -1.124912 -0.374971\n",
      "2019-01-04 -0.390038 -0.130013 -0.618772 -0.206257\n",
      "2019-01-05  0.332015  0.110672  0.309475  0.103158\n",
      "2019-01-06  0.133351  0.044450  0.732793  0.244264\n",
      "2019-01-07 -2.186343 -0.728781  1.287769  0.429256\n",
      "2019-01-08 -0.755425 -0.251808  1.683343  0.561114\n",
      "2019-01-09 -1.499792 -0.499931  1.722685  0.574228\n",
      "2019-01-10  0.240011  0.080004  1.432221  0.477407\n"
     ]
    }
   ],
   "source": [
    "r=df.rolling(window=3,min_periods=1)\n",
    "print(r[['A','B']].aggregate([np.sum,np.mean]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B\n",
      "2019-01-01  1.096083 -0.781778\n",
      "2019-01-02  0.315577 -0.872037\n",
      "2019-01-03  0.628062 -0.374971\n",
      "2019-01-04 -0.390038 -0.206257\n",
      "2019-01-05  0.332015  0.103158\n",
      "2019-01-06  0.133351  0.244264\n",
      "2019-01-07 -2.186343  0.429256\n",
      "2019-01-08 -0.755425  0.561114\n",
      "2019-01-09 -1.499792  0.574228\n",
      "2019-01-10  0.240011  0.477407\n"
     ]
    }
   ],
   "source": [
    "# 将不同的函数应用于DataFrame的不同列\n",
    "r=df.rolling(window=3,min_periods=1)\n",
    "print(r.aggregate({'A':np.sum,'B':np.mean}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.276259  0.484900 -1.256257\n",
      "b -1.229486  1.024699  2.130240\n",
      "c -0.809921  0.266810 -0.363503\n",
      "d -0.245248  0.227034 -1.370356\n",
      "e  1.823196  0.382441 -0.319045\n",
      "f       NaN       NaN       NaN\n",
      "g       NaN       NaN       NaN\n",
      "h       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# 数据丢失(缺失)在现实生活中总是一个问题。 \n",
    "# 机器学习和数据挖掘等领域由于数据缺失导致的数据质量差，\n",
    "# 在模型预测的准确性上面临着严重的问题。 \n",
    "# 在这些领域，缺失值处理是使模型更加准确和有效的重点。\n",
    "# 何时以及为什么数据丢失？\n",
    "# 想象一下有一个产品的在线调查。很多时候，人们不会分享与他们有关的所有信息。 \n",
    "# 很少有人分享他们的经验，但不是他们使用产品多久;\n",
    "# 很少有人分享使用产品的时间，经验，但不是他们的个人联系信息。\n",
    "# 因此，以某种方式或其他方式，总会有一部分数据总是会丢失，这是非常常见的现象。\n",
    "\n",
    "df=pd.DataFrame(np.random.randn(5,3),\n",
    "                index=['a','b','c','d','e'],\n",
    "                columns=['one','two','three']\n",
    "               )\n",
    "df=df.reindex(['a','b','c','d','e','f','g','h'])\n",
    "print(df)\n",
    "# 使用重构索引(reindexing)，创建了一个缺少值的DataFrame。 \n",
    "# 在输出中，NaN表示不是数字的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    False\n",
      "b    False\n",
      "c    False\n",
      "d    False\n",
      "e    False\n",
      "f     True\n",
      "g     True\n",
      "h     True\n",
      "Name: one, dtype: bool\n",
      "*********************************************\n",
      "a     True\n",
      "b     True\n",
      "c     True\n",
      "d     True\n",
      "e     True\n",
      "f    False\n",
      "g    False\n",
      "h    False\n",
      "Name: one, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 检查缺失值\n",
    "# 为了更容易地检测缺失值(以及跨越不同的数组dtype)，\n",
    "# Pandas提供了isnull()和notnull()函数，\n",
    "# 它们也是Series和DataFrame对象的方法 -\n",
    "print(df['one'].isnull())\n",
    "\n",
    "print('***'*15)\n",
    "print(df['one'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.185199666507\n"
     ]
    }
   ],
   "source": [
    "# 缺少数据的计算\n",
    "# 在求和数据时，NA将被视为0\n",
    "# 如果数据全部是NA，那么结果将是NA\n",
    "print(df['one'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "0  NaN  NaN\n",
      "1  NaN  NaN\n",
      "2  NaN  NaN\n",
      "3  NaN  NaN\n",
      "4  NaN  NaN\n",
      "5  NaN  NaN\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(index=[0,1,2,3,4,5],columns=['one','two'])\n",
    "print(df)\n",
    "print(df['one'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.053849 -1.400870  0.355712\n",
      "b       NaN       NaN       NaN\n",
      "c -0.727265  0.397265  0.151282\n",
      "NaN 被 0 替换\n",
      "        one       two     three\n",
      "a  0.053849 -1.400870  0.355712\n",
      "b  0.000000  0.000000  0.000000\n",
      "c -0.727265  0.397265  0.151282\n"
     ]
    }
   ],
   "source": [
    "# 清理/填充缺少数据\n",
    "\n",
    "# Pandas提供了各种方法来清除缺失的值。\n",
    "# fillna()函数可以通过几种方法用非空数据“填充”NA值，在下面的章节中将学习和使用。\n",
    "# 用标量值替换NaN\n",
    "# 以下程序显示如何用0替换NaN。\n",
    "df=pd.DataFrame(np.random.randn(3,3),index=['a','c','e'],columns=['one','two','three'])\n",
    "df=df.reindex(['a','b','c'])\n",
    "print(df)\n",
    "print(\"NaN 被 0 替换\")\n",
    "print(df.fillna(0))\n",
    "# 在这里填充零值; 当然，也可以填写任何其他的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.299259  0.544685  0.433692\n",
      "b       NaN       NaN       NaN\n",
      "c -0.206210  1.262537  0.257583\n",
      "        one       two     three\n",
      "a -0.299259  0.544685  0.433692\n",
      "b -0.299259  0.544685  0.433692\n",
      "c -0.206210  1.262537  0.257583\n"
     ]
    }
   ],
   "source": [
    "# 填写NA前进和后退\n",
    "# 使用重构索引章节讨论的填充概念，来填补缺失的值。\n",
    "df=pd.DataFrame(np.random.randn(3,3),index=['a','c','e'],columns=['one','two','three'])\n",
    "df=df.reindex(['a','b','c'])\n",
    "print(df)\n",
    "print(df.fillna(method='pad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.052090  1.104106  0.594668\n",
      "b       NaN       NaN       NaN\n",
      "c  2.159094  2.861799 -0.555430\n",
      "        one       two     three\n",
      "a  0.052090  1.104106  0.594668\n",
      "b  2.159094  2.861799 -0.555430\n",
      "c  2.159094  2.861799 -0.555430\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(np.random.randn(3,3),index=['a','c','e'],columns=['one','two','three'])\n",
    "df=df.reindex(['a','b','c'])\n",
    "print(df)\n",
    "print(df.fillna(method='backfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -1.202728 -0.482974 -0.719680\n",
      "c -0.236108  0.784497 -1.771000\n",
      "e -0.147481 -1.395533  1.296816\n",
      "f  2.333296  0.479130 -1.436962\n",
      "h -0.727004 -0.396933 -0.366332\n"
     ]
    }
   ],
   "source": [
    "# 丢失缺少的值\n",
    "\n",
    "# 如果只想排除缺少的值，则使用dropna函数和axis参数。 \n",
    "# 默认情况下，axis = 0，即在行上应用，\n",
    "# 这意味着如果行内的任何值是NA，那么整个行被排除。\n",
    "\n",
    "df=pd.DataFrame(np.random.randn(5,3),\n",
    "               index=['a','c','e','f','h'],\n",
    "               columns=['one','two','three'])\n",
    "df=df.reindex(['a','b','c','d','e','f','g','h'])\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [a, b, c, d, e, f, g, h]\n"
     ]
    }
   ],
   "source": [
    "# 丢失缺少的值\n",
    "\n",
    "# 如果只想排除缺少的值，则使用dropna函数和axis参数。 \n",
    "# 默认情况下，axis = 0，即在行上应用，\n",
    "# 这意味着如果行内的任何值是NA，那么整个行被排除。\n",
    "\n",
    "df=pd.DataFrame(np.random.randn(5,3),\n",
    "               index=['a','c','e','f','h'],\n",
    "               columns=['one','two','three'])\n",
    "df=df.reindex(['a','b','c','d','e','f','g','h'])\n",
    "print(df.dropna(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    one   two\n",
      "0    10  1000\n",
      "1    20     0\n",
      "2    30    30\n",
      "3    40    40\n",
      "4    50    50\n",
      "5  2000    60\n",
      "   one  two\n",
      "0   10   10\n",
      "1   20    0\n",
      "2   30   30\n",
      "3   40   40\n",
      "4   50   50\n",
      "5   60   60\n"
     ]
    }
   ],
   "source": [
    "# 替换丢失(或)通用值\n",
    "# 很多时候，必须用一些具体的值取代一个通用的值。可以通过应用替换方法来实现这一点。\n",
    "# 用标量值替换NA是fillna()函数的等效行为。\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'one':[10,20,30,40,50,2000],\n",
    "    'two':[1000,0,30,40,50,60]\n",
    "})\n",
    "print(df)\n",
    "print(df.replace({1000:10,2000:60}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Point  Rank    Team  Year\n",
      "0     54     1  Riders  2012\n",
      "1     43     2  Riders  2013\n",
      "2     98     3  Devils  2014\n",
      "3     63     4   Kings  2015\n",
      "4     65     5   Kings  2015\n",
      "5     72     6   Kings  2017\n",
      "6     32     1  Riders  2018\n"
     ]
    }
   ],
   "source": [
    "# 任何分组(groupby)操作都涉及原始对象的以下操作之一。它们是 -\n",
    "# 分割对象\n",
    "# 应用一个函数\n",
    "# 结合的结果\n",
    "# 在许多情况下，我们将数据分成多个集合，并在每个子集上应用一些函数。在应用函数中，可以执行以下操作 -\n",
    "# 聚合 - 计算汇总统计\n",
    "# 转换 - 执行一些特定于组的操作\n",
    "# 过滤 - 在某些情况下丢弃数据\n",
    "# 下面来看看创建一个DataFrame对象并对其执行所有操作 -\n",
    "\n",
    "ipl_data={\n",
    "    'Team':['Riders','Riders','Devils','Kings','Kings','Kings','Riders'],\n",
    "    'Rank':[1,2,3,4,5,6,1],\n",
    "    'Year':[2012,2013,2014,2015,2015,2017,2018],\n",
    "    'Point':[54,43,98,63,65,72,32]\n",
    "}\n",
    "df=pd.DataFrame(ipl_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.DataFrameGroupBy object at 0x0000000016935EF0>\n"
     ]
    }
   ],
   "source": [
    "# 将数据拆分成组\n",
    "# Pandas对象可以分成任何对象。有多种方式来拆分对象，如 -\n",
    "# obj.groupby(‘key’)\n",
    "# obj.groupby([‘key1’,’key2’])\n",
    "# obj.groupby(key,axis=1)\n",
    "# 现在来看看如何将分组对象应用于DataFrame对象\n",
    "print(df.groupby(ipl_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Devils': Int64Index([2], dtype='int64'), 'Kings': Int64Index([3, 4, 5], dtype='int64'), 'Riders': Int64Index([0, 1, 6], dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "# 查看分组\n",
    "print(df.groupby('Team').groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Devils', 2014): Int64Index([2], dtype='int64'), ('Kings', 2015): Int64Index([3], dtype='int64'), ('Kings', 2016): Int64Index([4], dtype='int64'), ('Kings', 2017): Int64Index([5], dtype='int64'), ('Riders', 2012): Int64Index([0], dtype='int64'), ('Riders', 2013): Int64Index([1], dtype='int64'), ('Riders', 2018): Int64Index([6], dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "# 按多列分组 -\n",
    "print(df.groupby(['Team','Year']).groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "   Point  Rank    Team  Year\n",
      "0     54     1  Riders  2012\n",
      "2013\n",
      "   Point  Rank    Team  Year\n",
      "1     43     2  Riders  2013\n",
      "2014\n",
      "   Point  Rank    Team  Year\n",
      "2     98     3  Devils  2014\n",
      "2015\n",
      "   Point  Rank   Team  Year\n",
      "3     65     4  Kings  2015\n",
      "4     65     5  Kings  2015\n",
      "2017\n",
      "   Point  Rank   Team  Year\n",
      "5     72     6  Kings  2017\n",
      "2018\n",
      "   Point  Rank    Team  Year\n",
      "6     32     1  Riders  2018\n"
     ]
    }
   ],
   "source": [
    "# 迭代遍历分组\n",
    "# 使用groupby对象，可以遍历类似itertools.obj的对象。\n",
    "grouped=df.groupby('Year')\n",
    "for name,group in grouped:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Point  Rank   Team  Year\n",
      "3     65     4  Kings  2015\n",
      "4     65     5  Kings  2015\n"
     ]
    }
   ],
   "source": [
    "# 选择一个分组\n",
    "# 使用get_group()方法，可以选择一个组。参考以下示例代码\n",
    "print(grouped.get_group(2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2012    54\n",
      "2013    43\n",
      "2014    98\n",
      "2015    65\n",
      "2017    72\n",
      "2018    32\n",
      "Name: Point, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 聚合\n",
    "# 聚合函数为每个组返回单个聚合值。当创建了分组(group by)对象，\n",
    "# 就可以对分组数据执行多个聚合操作。\n",
    "# 一个比较常用的是通过聚合或等效的agg方法聚合 -\n",
    "\n",
    "print(grouped['Point'].agg(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Point  Rank  Year\n",
      "Team                     \n",
      "Devils      1     1     1\n",
      "Kings       3     3     3\n",
      "Riders      3     3     3\n"
     ]
    }
   ],
   "source": [
    "# 另一种查看每个分组的大小的方法是应用size()函数 \n",
    "grouped=df.groupby('Team')\n",
    "print(grouped.agg(np.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sum       mean        std\n",
      "Team                             \n",
      "Devils   98  98.000000        NaN\n",
      "Kings   200  66.666667   4.725816\n",
      "Riders  129  43.000000  11.000000\n"
     ]
    }
   ],
   "source": [
    "# 一次应用多个聚合函数\n",
    "# 通过分组系列，还可以传递函数的列表或字典来进行聚合，并生成DataFrame作为输出\n",
    "agg=grouped['Point'].agg([np.sum,np.mean,np.std])\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Point       Rank       Year\n",
      "0  10.000000  -5.773503  -7.258662\n",
      "1   0.000000  11.547005  -4.147807\n",
      "2        NaN        NaN        NaN\n",
      "3  -7.758802 -10.000000  -5.773503\n",
      "4  -3.526728   0.000000  -5.773503\n",
      "5  11.285530  10.000000  11.547005\n",
      "6 -10.000000  -5.773503  11.406469\n"
     ]
    }
   ],
   "source": [
    "# 转换\n",
    "# 分组或列上的转换返回索引大小与被分组的索引相同的对象。\n",
    "# 因此，转换应该返回与组块大小相同的结果。\n",
    "grouped=df.groupby('Team')\n",
    "score=lambda x: (x-x.mean())/x.std()*10\n",
    "print(grouped.transform(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Point  Rank    Team  Year\n",
      "0     54     1  Riders  2012\n",
      "1     43     2  Riders  2013\n",
      "3     63     4   Kings  2015\n",
      "4     65     5   Kings  2015\n",
      "5     72     6   Kings  2017\n",
      "6     32     1  Riders  2018\n"
     ]
    }
   ],
   "source": [
    "# 过滤\n",
    "# 过滤根据定义的标准过滤数据并返回数据的子集。filter()函数用于过滤数据。\n",
    "filter=df.groupby('Team').filter(lambda x: len(x) >= 3)\n",
    "print(filter)\n",
    "# 在上述过滤条件下，要求返回三次以上参加IPL的队伍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
